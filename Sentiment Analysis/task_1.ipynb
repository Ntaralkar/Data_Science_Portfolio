{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Reconstruct the Original Meeting Transcripts\n",
    "\n",
    "The original meeting transcripts are stored in three different types of XML files, which are ending with \".words.xml\", \".topic.xml\" and \".segments.xml\". (The details about the three types of files can be found in Section 3 below). The task here is to reconstruct the original meeting transcripts with the corresponding topical and paragraph boundaries from these files. Please note that\n",
    "\n",
    "- A meeting transcript must be generated for each of the \"*.topic.xml\" file. For example, \"ES2002a.txt\" will be generated for \"ES2002a.topic.xml\".\n",
    "- All the generated meeting transcripts with the \".txt\" file extension must be saved in the folder \"txt_files\".\n",
    "- The topical boundaries must be denoted with \"**********\"(i.e., 10 asterisks).\n",
    "- All the tokens, including punctuations, must be separated by a white space. For example, \"Alright , okay . Okay .\"\n",
    "- Besides the topical boundaries, the paragraph boundaries must also be reconstructed with the \"*.segments.xml\" file.\n",
    "- The input files to your notebook \"task_1.ipynb\" must be the three types of XML files. The output must be the meeting - - transcripts saved in a set of txt files.\n",
    "- A sample meeting transcript is provided in the \"txt_file\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python Libraries\n",
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#string to store file content\n",
    "Word_string = \"\" \n",
    "\n",
    "#initialising folder path\n",
    "path = 'topics/' \n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    #search for xml files in the folder defined above\n",
    "    if not filename.endswith('.xml'): continue\n",
    "    fullname = os.path.join(path, filename)\n",
    "    #A variable to store file name\n",
    "    output_file=re.search('(.*).topic',filename).group(1)\n",
    "    #Reading all topic files\n",
    "    f = open(fullname, 'r')\n",
    "    #using xml tree to parse the xml files\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    temp = \"\"\n",
    "    for child in root:\n",
    "        for x in child.iter('{http://nite.sourceforge.net/}child'):\n",
    "            for key, value in x.items():\n",
    "                #Regular expression to get the filename, start and end number from topic files\n",
    "                twords = re.search('(.*)#id\\(.*words(\\d+)\\)..id\\(.*words(\\d+)\\)|(.*)#id\\(.*words(\\d+)\\)', value)\n",
    "                if twords.group(1) != None:\n",
    "                    file_name = twords.group(1)\n",
    "                    start_word = int(twords.group(2))\n",
    "                    end_word = int(twords.group(3))\n",
    "                else:\n",
    "                    file_name = twords.group(4)\n",
    "                    start_word = int(twords.group(5))\n",
    "                    end_word = int(twords.group(5))\n",
    "                #stores file name\n",
    "                new_file_name = re.search('(.*)words', file_name).group(1)\n",
    "                \n",
    "                #Parsing Segments XML files\n",
    "                seg_parse = ET.parse('segments/'+ new_file_name + \"segments.xml\")\n",
    "                seg_root = seg_parse.getroot()\n",
    "                for x in seg_root:\n",
    "                    #Extracting the contents from Segments XML files\n",
    "                    for y in x.iter('{http://nite.sourceforge.net/}child'):\n",
    "                        for k, v in y.items():\n",
    "                            #Regular Expression to extract start and end numbers from Segments XML file\n",
    "                            tsegs = re.search('(.*)#id\\(.*words(\\d+)\\)..id\\(.*words(\\d+)\\)|(.*)#id\\(.*words(\\d+)\\)', v)\n",
    "\n",
    "                            if tsegs.group(1) != None:\n",
    "                                start_seg = int(tsegs.group(2))\n",
    "                                end_seg = int(tsegs.group(3))\n",
    "                            else:\n",
    "                                start_seg = int(tsegs.group(5))\n",
    "                                end_seg = int(tsegs.group(5))\n",
    "                            \n",
    "                            #Condition, to check start ,end words and Segments\n",
    "                            if start_word <= start_seg and end_word >= end_seg or start_seg <= end_word and end_seg >= start_word:\n",
    "                                \n",
    "                                #Parsing Word XML files\n",
    "                                words_parse = ET.parse('words/' + new_file_name+ \"words.xml\")\n",
    "                                words_root = words_parse.getroot()\n",
    "                                \n",
    "                                #Extracting the information from w-tag from words XML files\n",
    "                                for xwords in words_root.iter(tag='w'):\n",
    "                                    word_value = xwords.attrib.get('{http://nite.sourceforge.net/}id')\n",
    "                                    \n",
    "                                    #WordNumber stores index of each line in word file\n",
    "                                    WordNumber = int(re.search('.*words(\\d+)', word_value).group(1))\n",
    "                                    \n",
    "                                    #check for topic and segment boundaries\n",
    "                                    if WordNumber >= start_seg and WordNumber <= end_seg and WordNumber <= end_word and WordNumber >= start_word:\n",
    "                                        #storing the information text into string\n",
    "                                        Word_string += \" \" + xwords.text\n",
    "                                Word_string += \"\\n\"\n",
    "                                temp += Word_string\n",
    "                                Word_string = ''\n",
    "                                \n",
    "        #Adding ********** after end of each topic\n",
    "        temp += \"**********\\n\"\n",
    "    \n",
    "    #Removing empty lines from the text\n",
    "    text_filtered = \"\\n\".join([text.rstrip() for text in temp.splitlines() if text.strip()])\n",
    "    #Writing to text files\n",
    "    with open('txt_files/'+ output_file + \".txt\", 'w') as f1:\n",
    "        f1.write(text_filtered.strip())\n",
    "    #closing file\n",
    "    f1.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this task will take few minutes. so please wait..Have Patience !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, following steps were performed:\n",
    "\n",
    "- Reading all the topic xml files from topic folder. File name, start word and end word was obtained from the topic child tags using regex.\n",
    "- After that segement xml files were read and corresponding start and end segement was recorded.\n",
    "- For each topic, each corresponding child start and end word boundaries was compared with the start and end segment boundaries.For each topic file, corresponding segment and words file was referred. All words which lie within the segment and topic boundaries were stored in a string.\n",
    "For example:\n",
    "Consider Es2002a.topic.xml file, \n",
    "\n",
    "nite:child href=\"ES2002a.B.words.xml#id(ES2002a.B.words0)..id(ES2002a.B.words71)\"/>\n",
    "\n",
    "which has a start word as 0 and end word boundary as 71. Its corresponding segement boundaries are \n",
    "\n",
    "  nite:child href=\"ES2002a.B.words.xml#id(ES2002a.B.words0)..id(ES2002a.B.words1)\n",
    "  nite:child href=\"ES2002a.B.words.xml#id(ES2002a.B.words2)..id(ES2002a.B.words3)\n",
    "  nite:child href=\"ES2002a.B.words.xml#id(ES2002a.B.words4)..id(ES2002a.B.words71)\n",
    "\n",
    "Therefore all words in the words file which lie within the topic boudaries are stored in a string. After every segment break is given. \n",
    "\n",
    "The output of file will be like.\n",
    "\n",
    "Okay .\n",
    " Right .\n",
    " Um well this is the kick-off meeting for our our project . Um and um this is just what we're gonna be doing over the next twenty five minutes . Um so first of all , just to kind of make sure that we all know each other , I'm Laura and I'm the project manager . Do you want to introduce yourself again ?\n",
    " Mm-hmm .\n",
    " Great .\n",
    " Hi , I'm David and I'm supposed to be an industrial designer .\n",
    " Okay .\n",
    " And I'm Andrew and I'm uh our marketing\n",
    " Um I'm Craig and I'm User Interface .\n",
    " expert .\n",
    "\"**********\"\n",
    "\n",
    "The subtopics will be considered in the main topic. After every topic, 10 * aestricks marks are added to indicate the end of one topic. Simillarly, all topics files are read and corresponding 139 text files are generated as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
