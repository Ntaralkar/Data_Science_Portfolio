{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Generate Sparse Representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Task 2.1*\n",
    "\n",
    "The aim of this task is to build sparse representations for the meeting transcripts generated in task 1, which includes word tokenization, vocabulary generation, and the generation of sparse representations. Please note that \n",
    "- The word tokenization must use the following regular expression, \"\\w+(?:[-']\\w+)?\", and all the words must be converted into the lower case.\n",
    "- The stop words list (i.e, stopwords_en.txt) provided in the zip file must be used.\n",
    "- The words, whose document frequencies are greater than 132, must be removed.\n",
    "- Generating multi-word phrases (i.e., collocations) are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python Libraries\n",
    "import glob\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-hold',\n",
       " 'a_a_',\n",
       " 'a_a_s',\n",
       " 'a_m_i_',\n",
       " 'a_n_',\n",
       " 'a_p_o_g_e_e_',\n",
       " 'a_s',\n",
       " 'a_s_r_',\n",
       " 'a_v_',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbie',\n",
       " 'abbing',\n",
       " 'abbreviations',\n",
       " 'abdul',\n",
       " 'abigail',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abo',\n",
       " 'abou',\n",
       " 'abrupt',\n",
       " 'abs',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abused',\n",
       " 'abut',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'acce',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentu',\n",
       " 'accentuate',\n",
       " 'accept',\n",
       " 'acceptability',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessoire',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'acco',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplishing',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accu',\n",
       " 'accumulate',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accustomed',\n",
       " 'ach',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieving',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acquai',\n",
       " 'acquaintance',\n",
       " 'acquainted',\n",
       " 'acronyms',\n",
       " 'act',\n",
       " 'acti',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'action-ey',\n",
       " 'actions',\n",
       " 'actiony',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actu',\n",
       " 'actua',\n",
       " 'actual',\n",
       " 'acu',\n",
       " 'acupressure',\n",
       " 'acupressures',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapting',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'adaptors',\n",
       " 'add',\n",
       " 'add-on',\n",
       " 'add-ons',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addit',\n",
       " 'additi',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adds-on',\n",
       " 'ademesoye',\n",
       " 'adequate',\n",
       " 'adhere',\n",
       " 'adjourned',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adm',\n",
       " 'admin',\n",
       " 'administrate',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'ado',\n",
       " 'adopted',\n",
       " 'adopters',\n",
       " 'adopting',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'adv',\n",
       " 'adva',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventurous',\n",
       " 'adver',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aerobics',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'aff',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affects',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affranchis',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afro',\n",
       " 'after-sales',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'agai',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'agnes',\n",
       " \"agnes's\",\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah-ha',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahmet',\n",
       " 'ahold',\n",
       " 'ahs',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'air',\n",
       " 'air-conditioners',\n",
       " 'airbag',\n",
       " 'aircraft',\n",
       " 'airport',\n",
       " 'ajax',\n",
       " 'aku',\n",
       " 'al-hasred',\n",
       " 'alarm',\n",
       " \"alarm's\",\n",
       " 'alarm-clock',\n",
       " 'alastair',\n",
       " 'alessi',\n",
       " 'alf',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'aligned',\n",
       " 'aligns',\n",
       " 'alima',\n",
       " 'alimentation',\n",
       " 'alive',\n",
       " 'alkaline',\n",
       " \"all's\",\n",
       " 'all-in',\n",
       " 'all-purpose',\n",
       " 'all-yellow',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'allo',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'alloy',\n",
       " 'alls',\n",
       " 'almo',\n",
       " 'alo',\n",
       " 'alphabet',\n",
       " 'alphabetically',\n",
       " 'alr',\n",
       " 'alread',\n",
       " 'alri',\n",
       " 'alrigh',\n",
       " 'alright',\n",
       " 'alrighty',\n",
       " 'als',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternates',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'altogether',\n",
       " 'aluminium',\n",
       " 'amadeus',\n",
       " 'amauto',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambitious',\n",
       " 'ambivalent',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amina',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amplification',\n",
       " 'amplified',\n",
       " 'amplifier',\n",
       " 'amplifiers',\n",
       " 'amplifies',\n",
       " 'amplify',\n",
       " 'amplitude',\n",
       " 'amuse',\n",
       " 'amusing',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analyse',\n",
       " 'analysed',\n",
       " 'analysing',\n",
       " 'analysis',\n",
       " 'anar',\n",
       " 'andre',\n",
       " 'andrei',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'angeles',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angular',\n",
       " 'anim',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animation',\n",
       " 'anna',\n",
       " 'annette',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'ano',\n",
       " 'anon',\n",
       " 'anonymous',\n",
       " 'anonymously',\n",
       " 'anoth',\n",
       " 'anothers',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'antek',\n",
       " 'antenna',\n",
       " 'antennas',\n",
       " 'anthony',\n",
       " 'anthropology',\n",
       " 'anti',\n",
       " 'anti-going',\n",
       " 'anti-r_s_i_',\n",
       " 'anti-slip',\n",
       " 'anti-stress',\n",
       " 'anti-technology',\n",
       " 'anti-theft',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'antlers',\n",
       " 'ants',\n",
       " 'anyb',\n",
       " 'anybo',\n",
       " \"anybody's\",\n",
       " 'anymore',\n",
       " \"anyone's\",\n",
       " 'anyth',\n",
       " 'anythi',\n",
       " 'anyti',\n",
       " 'anytime',\n",
       " 'anyw',\n",
       " 'apar',\n",
       " 'aparata',\n",
       " 'apartment',\n",
       " \"apartment's\",\n",
       " 'ape',\n",
       " 'apes',\n",
       " 'aphorism',\n",
       " 'apocalypse',\n",
       " 'apologies',\n",
       " 'apop',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appearan',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appendix',\n",
       " 'apple',\n",
       " \"apple's\",\n",
       " \"apple've\",\n",
       " 'apple-shaped',\n",
       " 'apples',\n",
       " 'applet',\n",
       " 'appliance',\n",
       " 'appliances',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appreciated',\n",
       " 'apprehensive',\n",
       " 'apprentice',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriately',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'approximation',\n",
       " 'april',\n",
       " 'aquaintance',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'architectural',\n",
       " 'archives',\n",
       " 'arcs',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argumentation',\n",
       " 'arguments',\n",
       " 'arised',\n",
       " 'arises',\n",
       " 'arithmetic',\n",
       " 'arizona',\n",
       " 'arlo',\n",
       " 'arm',\n",
       " 'armchair',\n",
       " 'armchairs',\n",
       " 'army',\n",
       " 'aro',\n",
       " 'arou',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'arrested',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrow',\n",
       " \"arrow's\",\n",
       " 'arrows',\n",
       " 'arse',\n",
       " 'arses',\n",
       " 'art',\n",
       " 'arthritic',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulated',\n",
       " 'articulation',\n",
       " 'articulators',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'ascension',\n",
       " 'ascensions',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asked',\n",
       " 'asks',\n",
       " 'asleeps',\n",
       " 'aspe',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'asse',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembler',\n",
       " 'assembly',\n",
       " 'assertive',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assistants',\n",
       " 'associate',\n",
       " 'associating',\n",
       " 'association',\n",
       " 'assu',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assumptions',\n",
       " 'astonishing',\n",
       " 'astray',\n",
       " 'ate',\n",
       " 'athe',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attaches',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attent',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attractable',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attractiveness',\n",
       " 'attracts',\n",
       " 'attributed',\n",
       " 'attributes',\n",
       " 'aubergines',\n",
       " 'audi',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'audio-visual',\n",
       " 'australia',\n",
       " 'authoris',\n",
       " 'authorisation',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'automac',\n",
       " 'automatic',\n",
       " 'automatical',\n",
       " 'automatically',\n",
       " 'autonomy',\n",
       " 'autoseek',\n",
       " 'autumn',\n",
       " 'auxiliary',\n",
       " 'avai',\n",
       " 'avail',\n",
       " 'availa',\n",
       " 'availability',\n",
       " 'availables',\n",
       " 'avenue',\n",
       " 'avera',\n",
       " 'average',\n",
       " 'aviation',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'avoidable',\n",
       " 'avoiding',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awesome',\n",
       " 'awesomest',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'axes',\n",
       " 'axially',\n",
       " 'axis',\n",
       " 'aye',\n",
       " 'azerty',\n",
       " 'b_b_c_',\n",
       " 'b_s_c_',\n",
       " 'baba',\n",
       " \"baba's\",\n",
       " 'babe',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'baby-proof',\n",
       " 'bacal',\n",
       " 'back',\n",
       " 'back-and',\n",
       " 'back-fire',\n",
       " 'back-forward',\n",
       " 'back-lights',\n",
       " 'back-lit',\n",
       " 'back-up',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlight',\n",
       " 'backlighting',\n",
       " 'backlights',\n",
       " 'backs',\n",
       " 'backside',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'baco',\n",
       " 'bad',\n",
       " 'badg',\n",
       " 'badge',\n",
       " 'badger',\n",
       " \"badger's\",\n",
       " 'badgers',\n",
       " 'badging',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'bahamas',\n",
       " 'bake',\n",
       " 'bal',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'balcony',\n",
       " 'bald',\n",
       " 'ball',\n",
       " 'ball-shaped',\n",
       " 'balley',\n",
       " 'balloon',\n",
       " 'ballpark',\n",
       " 'balls',\n",
       " 'bana',\n",
       " 'banana',\n",
       " \"banana's\",\n",
       " 'banana-bando',\n",
       " 'banana-based',\n",
       " 'banana-esque',\n",
       " 'banana-man',\n",
       " 'banana-mando',\n",
       " 'banana-shaped',\n",
       " 'bananarama',\n",
       " 'bananas',\n",
       " 'band',\n",
       " 'band-width',\n",
       " 'bang',\n",
       " 'bangladesh',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'banned',\n",
       " 'bar',\n",
       " 'bar-code',\n",
       " 'barbara',\n",
       " 'bare',\n",
       " 'bare-board',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barks',\n",
       " 'barney',\n",
       " 'baroque',\n",
       " 'bars',\n",
       " 'bart',\n",
       " 'bas',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashed',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basics',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bateer',\n",
       " 'bath',\n",
       " 'bathgate',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'baths',\n",
       " 'batter',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " \"battery's\",\n",
       " 'battery-powered',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'bay',\n",
       " 'be-back',\n",
       " 'be-backs',\n",
       " 'beach',\n",
       " 'beacon',\n",
       " 'beagle',\n",
       " 'beagles',\n",
       " 'beak',\n",
       " 'beam',\n",
       " 'beamer',\n",
       " 'beams',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bearing',\n",
       " 'bearings',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beatles',\n",
       " 'beauti',\n",
       " 'beautiful',\n",
       " \"beautiful's\",\n",
       " 'beauty',\n",
       " 'beaver',\n",
       " 'bec',\n",
       " 'beca',\n",
       " 'becasue',\n",
       " 'becau',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bee',\n",
       " 'beebies',\n",
       " 'beep',\n",
       " 'beeper',\n",
       " \"beeper's\",\n",
       " 'beeping',\n",
       " 'beeps',\n",
       " 'beer',\n",
       " 'bees',\n",
       " 'bef',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginni',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'begun',\n",
       " 'behave',\n",
       " 'behaviour',\n",
       " 'behi',\n",
       " 'beholden',\n",
       " 'beige',\n",
       " 'beings',\n",
       " 'bel',\n",
       " 'belgium',\n",
       " 'believes',\n",
       " 'bell',\n",
       " 'bella',\n",
       " 'bells',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bench-marker',\n",
       " 'benchmarking',\n",
       " 'bend',\n",
       " 'bendable',\n",
       " 'beneath',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bening',\n",
       " 'benjo',\n",
       " 'bent',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betcha',\n",
       " 'betenberg',\n",
       " 'betsy',\n",
       " 'betty',\n",
       " 'betwe',\n",
       " 'betweens',\n",
       " 'beware',\n",
       " 'bezzled',\n",
       " 'biased',\n",
       " 'bic',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bikes',\n",
       " 'bill',\n",
       " 'bingwings',\n",
       " 'binocular',\n",
       " 'bio-morphic',\n",
       " 'biology',\n",
       " 'biomorphic',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'biscuits',\n",
       " \"bit's\",\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'bla',\n",
       " 'black',\n",
       " \"black's\",\n",
       " 'blackberry',\n",
       " 'blackboard',\n",
       " 'blackpool',\n",
       " 'blacks',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blanks',\n",
       " 'blasting',\n",
       " 'bleep',\n",
       " 'bleeper',\n",
       " 'bleeps',\n",
       " 'blend',\n",
       " 'blended',\n",
       " 'blender',\n",
       " 'blends',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'bling',\n",
       " 'blink',\n",
       " 'blinking',\n",
       " 'blob',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blocks',\n",
       " 'blocky',\n",
       " 'bloggs',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blows',\n",
       " 'blue',\n",
       " \"blue's\",\n",
       " 'blue-based',\n",
       " 'blueberry',\n",
       " 'bluetooth',\n",
       " 'blunt',\n",
       " 'board',\n",
       " \"board's\",\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobby',\n",
       " 'bobs',\n",
       " 'bod',\n",
       " 'bode',\n",
       " 'bodies',\n",
       " 'body',\n",
       " \"body's\",\n",
       " 'bog',\n",
       " 'bogged',\n",
       " 'boil',\n",
       " 'bold',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bon',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bongiorno',\n",
       " 'bonjour',\n",
       " 'bonus',\n",
       " 'bonuses',\n",
       " 'boo',\n",
       " 'boo-hoo',\n",
       " 'book',\n",
       " 'book-cases',\n",
       " 'bookcase',\n",
       " 'booked',\n",
       " 'booklet',\n",
       " 'books',\n",
       " 'bookshelf',\n",
       " 'bookshelves',\n",
       " 'boom',\n",
       " 'boom-boa',\n",
       " 'boomers',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boosted',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'boring',\n",
       " 'borrow',\n",
       " 'borrowed',\n",
       " 'borrowing',\n",
       " 'boss',\n",
       " 'bosses',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'botched',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bothers',\n",
       " 'bottle',\n",
       " 'bottleneck',\n",
       " 'bottom',\n",
       " 'bottoms',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bought-on',\n",
       " 'bounce',\n",
       " 'bounced',\n",
       " 'bounces',\n",
       " 'bouncing',\n",
       " 'bouncy',\n",
       " 'bound',\n",
       " 'boundaries',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boxes',\n",
       " 'boxy',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'bra',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'brain-storm',\n",
       " 'brain-storming',\n",
       " 'brains',\n",
       " 'brainstorm',\n",
       " 'brainstormed',\n",
       " 'brainstorming',\n",
       " 'brake',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'branching',\n",
       " 'brand',\n",
       " 'brand-aware',\n",
       " 'branded',\n",
       " 'branding',\n",
       " 'brands',\n",
       " 'bravo',\n",
       " 'break',\n",
       " 'break-down',\n",
       " 'break-through',\n",
       " 'breakable',\n",
       " 'breakage',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " ...]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Initializing path \n",
    "path=\"txt_files/\"\n",
    "\n",
    "#initializing variables to store data\n",
    "final_data=[]\n",
    "#count=0\n",
    "stopwords_list=[]\n",
    "\n",
    "#Extracting stopwords file from stopwords_en.txt file and appending it to list\n",
    "stopWords_file = open(\"stopwords_en.txt\",\"r\")\n",
    "for word in stopWords_file.read().split():\n",
    "    stopwords_list.append(word)\n",
    "stopWords_file.close()\n",
    "\n",
    "#Taking only unique stop words from stopwords list\n",
    "stopwords_set = set(stopwords_list)\n",
    "\n",
    "#Reading all txt files\n",
    "for filename in os.listdir(path):\n",
    "    #string to store file content\n",
    "    data = ''\n",
    "    #count=count+1\n",
    "    filename = os.path.join(path, filename)\n",
    "    #Reading all files in txt_files folder\n",
    "    file = open(filename,\"r\")   \n",
    "    file_name = file.read().replace('\\n', '')\n",
    "    data = data + file_name \n",
    "    #closing the file\n",
    "    file.close()\n",
    "    #Converting data into lower case\n",
    "    data = data.lower()\n",
    "    #Tokenizing the data using RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\")\n",
    "    unigram_tokens = tokenizer.tokenize(data)\n",
    "    #Removing stopwords from the unigram tokens\n",
    "    stopwords_removed = [w for w in unigram_tokens if w not in stopwords_set]\n",
    "    Removed_tokens = [w for w in stopwords_removed if len(w)>=3] \n",
    "    final_data.extend(list(set(Removed_tokens)))\n",
    "\n",
    "\n",
    "index_dict={}\n",
    "#Counter to assign index value to tokens\n",
    "index_dict=Counter(final_data)\n",
    "index_dict_copy=dict(index_dict)\n",
    "\n",
    "#Removing words, whose document frequencies are greater than 132\n",
    "for key,value in index_dict.items():\n",
    "    if value>132:\n",
    "        del index_dict_copy[key]\n",
    "        \n",
    "final_tokens=[]\n",
    "for key in index_dict_copy:\n",
    "    final_tokens.append(key)\n",
    "\n",
    "#Sorting final tokens\n",
    "final_tokens.sort()\n",
    "\n",
    "final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding index\n",
    "vocab = []\n",
    "count = 0\n",
    "tokens = ''\n",
    "\n",
    "for i in range(0, len(final_tokens)):\n",
    "    tokens = final_tokens[i] + ':' + str(count)\n",
    "    vocab.append(tokens)\n",
    "    count = count + 1\n",
    "    \n",
    "#Writing to file\n",
    "vocab_file = open('vocab.txt', 'w')\n",
    "\n",
    "for item in vocab:\n",
    "    vocab_file.writelines(\"%s\\n\" % item)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In case the count in output vocab.txt is not 10304, please run second tab again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above task, following steps were performed:\n",
    "    \n",
    "\n",
    "- Reading stopwords file\n",
    "- Reading all text files generated from task 1\n",
    "- Converting the text into lower case\n",
    "- Then, tokenizing the data using RegexpTokenizer given in tutorials\n",
    "- Removing all stopwords from the unigram tokens\n",
    "- Removing words, whose document frequencies are greater than 132 and then sorting the data\n",
    "- Adding index to the tokens and writing to vocab.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Task 2.2*\n",
    "\n",
    "It contains the topic boundaries encoded in boolean vectors. For example, if a meeting transcript, \"ES2018d.txt\" contains 10 paragraphs in total after being preprocessed, and there are topic boundaries after the 2nd, 5th, and 7th paragraphs, the boolean vector must be \"ES2018d:0,1,0,0,1,0,1,0,0,1\". Every line in topic_seg.txt corresponds to one meeting transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to store file content\n",
    "final_Seg_string = \" \" \n",
    "\n",
    "path = 'txt_files/' #initialising folder path\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    #search for xml files in the folder defined above\n",
    "    if not filename.endswith('.txt'): continue\n",
    "    fullname = os.path.join(path, filename)\n",
    "    #Reading each text file\n",
    "    f = open(fullname, 'r')\n",
    "    #Extracting file name\n",
    "    file_name = filename.strip(\".txt\")\n",
    "    #list to store file content\n",
    "    data_list = []\n",
    "    #Reading each line from text file\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip()\n",
    "        data_list.append(line)\n",
    "    paragraph = len(data_list)\n",
    "    \n",
    "    #Creating a list with boolean 0\n",
    "    boolean_vector=[0] * paragraph\n",
    "    \n",
    "    #Obtaining the index position of aster\n",
    "    line_index = [i for i, x in enumerate(data_list) if x == \"**********\"]\n",
    "    \n",
    "    #Assigning 1 to positions before the occurence of aster\n",
    "    for index in line_index:\n",
    "        boolean_vector[index-1] = 1\n",
    "        \n",
    "    #Adding ':' to the file name\n",
    "    boolean_string=file_name+':'\n",
    "    \n",
    "    #Adding boolean values to the list followed by ','\n",
    "    for x in boolean_vector:\n",
    "        boolean_string=boolean_string + str(x) + ','\n",
    "        \n",
    "    boolean_string = boolean_string.rstrip(',')\n",
    "    final_Seg_string += boolean_string + '\\n'\n",
    "    \n",
    "#Writing the generated list of boolean vectors to the file\n",
    "topic_seg = open(\"topic_seg.txt\", 'w')\n",
    "topic_seg.write(final_Seg_string)\n",
    "topic_seg.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, following steps were performed:\n",
    "\n",
    "- All text files were read which were generated from task 1\n",
    "- A boolean vector was taken with values 0 and 1. 1s were assigned to those lines succeeded with 10 *'s, while 0's were assigned to all the remaining lines.\n",
    "For example, consider Es2002a.txt file. \n",
    "\n",
    "Okay .\n",
    " Right .\n",
    " Um well this is the kick-off meeting for our our project . Um and um this is just what we're gonna be doing over the next twenty five minutes . Um so first of all , just to kind of make sure that we all know each other , I'm Laura and I'm the project manager . Do you want to introduce yourself again ?\n",
    " Mm-hmm .\n",
    " Great .\n",
    " Hi , I'm David and I'm supposed to be an industrial designer .\n",
    " Okay .\n",
    " And I'm Andrew and I'm uh our marketing\n",
    " Um I'm Craig and I'm User Interface .\n",
    " expert .\n",
    "**********\n",
    "\n",
    "So for Okay, Right and every other line 0 was assigned, while 1 was assigned only to the line preceeding with 10 *'s. in this case 1 was assigned to expert.\n",
    "\n",
    "Output will be:\n",
    "\n",
    "ES2002a:0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0\n",
    "\n",
    "Simillarly, same operation was performed for rest of the files in the txt_files folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Task 2.3*\n",
    "\n",
    "Each txt file in the \"sparse_files\" folder corresponds to one of the meeting transcripts in the \"txt_files\" folder, and they have the same file name.  For example, \"./sparse_files/ES2002a.txt\" corresponds to \"./txt_files/ES2002a.txt\". Each file in \"/sparse_files\" contains the sparse representations for all its paragraphs as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing variables to store vocab words and count\n",
    "vocab_words=[]\n",
    "vocab_index=[]\n",
    "new_list=[]\n",
    "with open('vocab.txt') as f:\n",
    "    vocab_file_list = f.read().splitlines()\n",
    "\n",
    "\n",
    "for i in range(len(vocab_file_list)):\n",
    "    vocab_words.append(re.search('(.*):',vocab_file_list[i]).group(1))\n",
    "    vocab_index.append(re.search(':(\\d+)',vocab_file_list[i]).group(1))\n",
    "vocab_dict = dict(zip(vocab_words, vocab_index))\n",
    "\n",
    "\n",
    "path=\"txt_files/\"\n",
    "for filename in os.listdir(path):\n",
    "    file_name = filename\n",
    "    filename = os.path.join(path, filename)\n",
    "    \n",
    "    #reading text files\n",
    "    txt_files = open(filename,\"r\")\n",
    "    lines = txt_files.readlines()\n",
    "    txt_files.close()\n",
    "    \n",
    "    lines_list=[]\n",
    "    for line in lines:\n",
    "        line=line.strip().lower()\n",
    "        lines_list.append(line)\n",
    "    \n",
    "    #String to store data\n",
    "    final_string=''\n",
    "\n",
    "    #Iterate over each line in the file.\n",
    "    for line in lines_list:\n",
    "            if(line=='**********'):\n",
    "                pass\n",
    "            else:\n",
    "                lst=line.split(' ')\n",
    "                #Initialize dictionary to store words count\n",
    "                count_dict={}\n",
    "                #Counter to count frequency of occurence\n",
    "                count_dict=Counter(lst)\n",
    "                count_dict_copy={}\n",
    "                for key,value in count_dict.items():\n",
    "                    if key in vocab_dict:\n",
    "                        index=vocab_dict[key]\n",
    "                        count_dict_copy[index]=value\n",
    "                #Converting dictionary to string\n",
    "                string_values = ' '.join('{0}:{1}'.format(key, val) for key, val in count_dict_copy.items())\n",
    "                final_string += string_values +'\\n'\n",
    "    \n",
    "    #Removing any empty spaces or lines\n",
    "    final_string = \"\\n\".join([text.rstrip() for text in final_string.splitlines() if text.strip()])\n",
    "    \n",
    "    #Writing output to a text file\n",
    "    with open('sparse_files/'+ file_name + \".txt\", 'w') as f1:\n",
    "        f1.write(final_string)\n",
    "    \n",
    "    #closing file\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, following steps were performed:\n",
    "\n",
    "- vocab file genereated in above task was read and converted into dictionary\n",
    "- Text files were read from the txt_files, generated from the task 1 and converted into lower case and then appended to a list\n",
    "- Counter was used to count the frequency of occurence of words. The words from the vocab file were then compared with the words from the text files of the txt_files folder. \n",
    "- For each line, the frequency of occurence of words were noted.\n",
    "- Dictionary was converted into string and white space or empty lines were removed.\n",
    "- Final string then was written to text file with corresponding file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
